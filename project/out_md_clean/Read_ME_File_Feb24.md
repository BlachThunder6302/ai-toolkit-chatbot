# Table of Contents
- [# Read_ME_File_Feb24](#read-me-file-feb24)- [README File REVISED FEBRUARY 2024 I](#readme-file-revised-february-2024-i)- [Images on this page:](#images-on-this-page)- [Images on this page:](#images-on-this-page)- [Images on this page:](#images-on-this-page)- [Images on this page:](#images-on-this-page)- [Images on this page:](#images-on-this-page)- [Images on this page:](#images-on-this-page)- [Images on this page:](#images-on-this-page)- [Images on this page:](#images-on-this-page)- [README File www.ai-lawenforcement.org XVIII](#readme-file-www-ai-lawenforcement-org-xviii)- [Images on this page:](#images-on-this-page)
### # Read_ME_File_Feb24
### ## Page 1
### README File REVISED FEBRUARY 2024 I
### Images on this page:
\[image\]: media\Read_ME_File_Feb24\page-1-img-1.png

\[image\]: media\Read_ME_File_Feb24\page-1-img-2.png

\[image\]: media\Read_ME_File_Feb24\page-1-img-3.png

\[image\]: media\Read_ME_File_Feb24\page-1-img-4.png

### ## Page 2
DISCLAIMER The contents of this document are for information purposes only. INTERPOL and UNICRI assume no liability or responsibility for any inaccurate or incomplete information, nor for any actions taken in reliance thereon. The published material is distributed without warranty of any kind, either express or implied, and the responsibility for the interpretation and use of the material lies with the reader. In no event shall, INTERPOL or UNICRI be liable for damages arising from its use. INTERPOL and UNICRI take no responsibility for the content of any external website referenced in this publication or for any defamatory, offensive or misleading information which might be contained on these third-party websites. Any links to external websites do not constitute an endorsement by INTERPOL or UNICRI, and are only provided as a convenience. It is the responsibility of the reader to evaluate the content and usefulness of information obtained from other sites. The views, thoughts and opinions expressed in the content of this publication belong solely to the authors and do not necessarily reflect the views or policies of, nor do they imply any endorsement by, INTERPOL or the United Nations, their member countries or member states, their governing bodies, or contributory organizations. Therefore, INTERPOL and UNICRI carry no responsibility for the opinions expressed in this publication. INTERPOL and UNICRI do not endorse or recommend any product, process, or service. Therefore, mention of any products, processes, or services in this document cannot be construed as an endorsement or recommendation by INTERPOL or UNICRI. The designation employed and presentation of the material in this document do not imply the expression of any opinion whatsoever on the part of the Secretariat of the United Nations, UNICRI or INTERPOL, concerning the legal status of any country, territory, city or area of its authorities, or concerning the delimitation of its frontiers or boundaries. The contents of this document may be quoted or reproduced, provided that the source of information is acknowledged. INTERPOL and UNICRI would like to receive a copy of the document in which this publication is used or quoted.

### ## Page 3
FOREWORD In the continuously evolving realm of technology, Artificial Intelligence (AI) has emerged as a formidable force capable of reshaping almost every facet of society. In recent years, we have witnessed incredible progress in AI technologies and its potential as an asset, but also as a threat. AI’s immense power and potential benefits require a strong sense of responsibility, especially for law enforcement. As our society embraces these technological advancements, it becomes paramount to ensure that the deployment of AI in policing is guided by an unwavering commitment to upholding ethical standards, safeguarding human rights, and fostering fairness and transparency. Recognizing the concerns expressed by representatives from the global law enforcement community regarding the lack of guidance in utilizing AI, INTERPOL and the United Nations Interregional Crime and Justice Research Institute (UNICRI) have jointly developed this Toolkit for Responsible AI Innovation in Law Enforcement. The Toolkit aims to provide support and guidance to law enforcement agencies, enabling them to leverage AI in a trustworthy, lawful and responsible manner, providing a clear, pragmatic, and most of all useful guide. As a unique global platform for law enforcement cooperation, INTERPOL is committed to making both the physical and virtual realms safer. My thanks to everyone who contributed to the development of this AI Toolkit which exemplifies the collaborative efforts required to navigate the intricate landscape of AI in law enforcement.

### Images on this page:
\[image\]: media\Read_ME_File_Feb24\page-3-img-1.png

### ## Page 4
I particularly extend my gratitude and appreciation to UNICRI for their invaluable collaboration, unwavering support, and commitment to our shared goals. We look forward to continuing this fruitful partnership. INTERPOL’s databases are at the core of the services we offer member countries, so any way tools can help connect police with the right intelligence more efficiently merits being explored. Together with the recently established INTERPOL Responsible AI Lab, the Toolkit stands as a testament to INTERPOL’s ongoing commitment to fostering an innovative and proactive law enforcement culture. As INTERPOL celebrate its centenary, the AI Toolkit also highlights the Organization’s flexibility whilst remaining true to our founding principles as we coordinate global law enforcement efforts addressing the increasingly complex crime threat landscape of today, and tomorrow. JUERGEN STOCK Secretary General, INTERPOL

### Images on this page:
\[image\]: media\Read_ME_File_Feb24\page-4-img-1.png

### ## Page 5
FOREWORD We find ourselves in extraordinary times. Artificial Intelligence (AI) is visibly changing the dynamics of the world around us. It is exhilarating, inspiring, and promising, and yet, it also demands our utmost vigilance and responsibility – particularly in the law enforcement context, which is highly sensitive. UNICRI is working at the forefront of this technological revolution. As the United Nations research and training institute with a focus on crime prevention and criminal justice, we are heavily invested in responsible AI and ‘getting it right’. This flows from the commitment in the United Nations Charter to promote and encourage respect for human rights and fundamental freedoms for all, without discrimination. A key example of this commitment is UNESCO’s groundbreaking Recommendation on the Ethics of Artificial Intelligence, a unique framework adopted by all 193 Member States in 2021. At UNICRI, we have worked tirelessly in this direction since the establishment of our Centre for AI and Robotics in 2017. This Toolkit for Responsible AI Innovation in Law Enforcement is our contribution to shaping the trajectory of responsible AI innovation in law enforcement. We are proud to partner with INTERPOL on this crucial endeavour. INTERPOL has been the lynchpin of international police cooperation for 100 years, and it has been a key ally of the United Nations system since its own founding in 1945. INTERPOL is a trusted partner of UNICRI for many years already, enriching the depth and breadth of our joint work. Together we have produced an invaluable blueprint to guide the global law enforcement community to leverage the promise of AI in a human rights compliant and ethical manner. This has been our shared vision and mission since day one of our joint work on responsible AI innovation.

### Images on this page:
\[image\]: media\Read_ME_File_Feb24\page-5-img-1.png

### ## Page 6
Finally, this endeavour has benefitted greatly from the commitment and support of the European Union. Through the General Data Protection Regulation (GDPR), the European Commission’s High-Level Expert Group on Artificial Intelligence, the European AI Alliance, and the proposed European Artificial Intelligence Act, Europe has demonstrated its commitment to responsible AI, recognizing the need to balance innovation with ethics, human rights, and societal well-being. We now add one more example to that impressive list: the Toolkit for Responsible AI Innovation in Law Enforcement. As we stand at the precipice of this technological revolution, we bear witness to the immense opportunities and challenges of AI. By embracing the principles and guidance outlined in this AI Toolkit, we can harness the potential of AI in law enforcement to help improve public safety, prevent crime, and promote justice for victims. Together, let us strive towards a future where innovation and human rights go hand in hand, taking advantage of the benefits and mitigating the risks of AI, to build a safer and more equitable world for all. ANTONIA MARIA DE MEO Director, UNICRI

### Images on this page:
\[image\]: media\Read_ME_File_Feb24\page-6-img-1.png

### ## Page 7
README File What is the AI Toolkit? Artificial intelligence (AI) is transforming the world, and policing is no exception to this: law enforcement agencies in many parts of the world are already developing, acquiring and using different types of AI systems, tools, and technologies to support an increasingly broad range of activities. Whether for image, text and speech analysis or risk assessment, AI is already essential for many agencies, and it is on its way to becoming one of the fundamental operating tools of policing. The Toolkit for Responsible AI Innovation in Law Enforcement is a tailor-made set of resources for the global law enforcement community, developed by INTERPOL and UNICRI with the financial support of the European Union. Its objective is to support law enforcement agencies to navigate the complex task of institutionalizing responsible AI innovation and integrating AI systems into their work. It has been designed in full recognition of both the opportunities and the challenges that AI presents for the law enforcement community, and it is intended to offer support to agencies interested in or already committed to responsible AI innovation. More specifically, this AI Toolkit provides law enforcement agencies with a theoretical foundation on responsible AI innovation based on human rights law, ethics and policing principles, as well as several practical tools to support them with putting responsible AI innovation theory into practice at each and every stage of their AI journey. 6

### Images on this page:
\[image\]: media\Read_ME_File_Feb24\page-7-img-1.png

### ## Page 8
README File This AI Toolkit is comprised of seven individual standalone resources. Together, these resources provide agencies with the necessary knowledge and understanding to be able to benefit from the positive potential of these systems while navigating the possible challenges and risks, whatever the agency’s level of experience with AI. The resources have all been designed to be informative, practical and actionable, providing guidance and best practices to move forward along the path of responsible AI innovation. The seven resources are grouped into three categories (see the table): PRIMARY GUIDANCE SUPPORTING PRACTICAL TOOLS DOCUMENTS Introduction to Organizational Technical Reference Responsible AI Readiness Assessment Book Innovation Questionnaire Principles for Risk Assessment Responsible AI Questionnaire Innovation Responsible AI Organizational Innovation in Action Roadmap Workbook The AI Toolkit is designed to provide the law enforcement community with a balanced perspective on responsible AI innovation that is grounded in human rights, ethics, and established good policing principles, all contextualized with practical examples of law enforcement-specific use cases which are provided throughout the AI Toolkit. It is important to note that the AI Toolkit is not intended to create binding obligations or to limit or undermine any of an agency’s binding obligations under international or domestic law. Rather, the AI Toolkit provides guidance, considerations and recommendations to be followed voluntarily. Equally, the AI Toolkit is not intended to replace or subsume any of the management strategies, policies or procedures already in place in law enforcement agencies, such as project management, risk and needs analysis, data protection and assessment, or risk-benefit analysis. Instead, it is designed to complement existing institutional and organizational processes and procedures: it is most useful when used in conjunction with other relevant management tools. 7

### ## Page 9
README File Who is the AI Toolkit for? The intended primary users of the AI Toolkit are personnel in law enforcement agencies, whether local, regional or national. This includes a wide range of personnel – both officers and civilians – in various departments and units, from the end users of AI systems in operational units to innovation teams, legal divisions and procurement offices, as well as, in some cases, the chief of police and their executive leadership. However, it is also important to highlight the fact that ‘law enforcement’ can be a broad term. For the purposes of the AI Toolkit, ‘law enforcement’ refers to the police and other similar state authorities that exercise police functions such as investigating crimes, protecting people and property, and maintaining public order and safety. In some cases, the term ‘law enforcement’ may include border control authorities, corrections officers, or counter-terrorism entities, for example. In some cases, the judiciary, in particular prosecutors, is also considered to be part of ‘law enforcement’. While the AI Toolkit was not designed primarily with these latter kinds of ‘law enforcement’ users in mind, it may nevertheless be of value for these authorities when exercising police functions. It is crucial to note that, apart from law enforcement personnel, many other non-law enforcement stakeholders play a key role in implementing responsible AI innovation in law enforcement. These include technology developers in the private sector or academia, civil society, the general public, and other criminal justice actors such as the judiciary, prosecutors and lawyers – if they are not already considered part of ‘law enforcement’. The AI Toolkit has been developed with the role of these ‘secondary’ stakeholders in mind, and seeks to simultaneously increase general knowledge and awareness of the underlying themes of responsible AI innovation in law enforcement, demystify the issues involved, and facilitate more informed discussions among and between all groups of stakeholders. How to use the AI Toolkit? The resources within the AI Toolkit have been specifically designed as standalone resources, allowing each resource to be consulted independently of the others and at different times. This approach takes into account the fact that each agency’s experience with AI, and their journey towards responsible AI innovation, is unique. While some agencies may already be using AI 8

### ## Page 10
README File systems to support their day-to-day work and may have the corresponding in-house expertise, other agencies may still be getting to grips with general knowledge and understanding of AI and exploring the available technologies. This approach also allows for the fact that the AI Toolkit will be relevant for many different types of law enforcement personnel at different stages of the life cycle of an AI system. RECOMMENDED PATHWAY THROUGH THE AI TOOLKIT Although the resources within it are designed to be consulted independently, there is a recommended pathway through the AI Toolkit. 9

### Images on this page:
\[image\]: media\Read_ME_File_Feb24\page-10-img-1.png

### ## Page 11
README File This pathway begins with all AI Toolkit users – regardless of how familiar the agency or individual is with AI – getting acquainted with the concepts upon which the AI Toolkit is founded and the key terms that arise repeatedly throughout. With this in 1 mind, it is recommended that AI Toolkit users start by familiarizing themselves with the Introduction to Responsible AI Innovation and the Principles for Responsible AI Innovation, referring as needed to the Technical Reference Book for more technical detail on AI. Having established this foundation, it is recommended that each agency carries out a self-assessment of its organizational readiness using the Organizational Readiness Assessment Questionnaire, supported by the Organizational Roadmap. Again, it is 2 recommended that this assessment be conducted regardless of the level of experience that an agency already has regarding the use of AI systems. This exercise will help the agency to understand at what stage it is in terms of the necessary capabilities for beginning or continuing the journey toward responsible AI innovation. AI Toolkit users – particular those moving from a more general exploration of the opportunities AI systems present toward the actual deployment of an AI system – are then advised to move on to the Risk Assessment Questionnaire and the Responsible AI Innovation in Action Workbook. The Risk Assessment Questionnaire should be completed at the earliest opportunity during the life cycle of an AI system. This will provide the teams in charge within an agency with a solid understanding of the potential threats to individuals and communities associated with a specific AI use case, thus allowing them to better align 3 their decisions with the Principles for Responsible AI Innovation. Given that assessing risks is an iterative process, it is recommended that the Risk Assessment Questionnaire be conducted periodically. The Responsible AI Innovation in Action Workbook is designed to be an accompanying resource for each of the various stages of the life cycle of an AI system – from planning to deployment, use and monitoring, and anything else that may be involved – and for the different teams within an agency that may play a role in these stages. AI Toolkit users should regularly refer to the Workbook to help them put responsible AI innovation into practice and to track and document their goals and progress. The following table provides an overview of the main aims of each resource and a provisional list of the users that may find the resources valuable. This is intended to provide further support for agencies in determining when to consult each resource and who should be assigned the responsibility of familiarizing themselves with its content. 10

### ## Page 12
README File RESOURCE PURPOSE USER This resource provides Any individual or team in a basic overview of law enforcement agency important AI concepts and that is interested in learning Introduction to an understanding of what more about the importance Responsible responsible AI innovation of a responsible approach to AI Innovation means, its foundations, and its AI innovation and wants to significance in the context of understand the basis for such law enforcement. an approach. This resource serves as a Any individual or team in a foundation for the AI Toolkit. law enforcement agency The principles described working with or in relation to AI Principles for therein are aligned with systems, including the chief of Responsible policing principles to ensure police, the executive leadership, AI Innovation that AI systems are developed and others such as decisionand used for the benefit makers in senior management of society while protecting positions. human rights. This resource seeks to The chief of police and help law enforcement executive leadership, as well agencies to understand as decision-makers in senior what elements should be in management positions place in order to pursue a outside the executive responsible approach to the Organizational leadership, particularly those development, procurement, Roadmap in technology and innovation and/or deployment of AI units that are responsible systems. Its goal is to support for the deployment of AI law enforcement agencies systems. with preparing to apply the Principles for Responsible AI Innovation. 11

### ## Page 13
README File The chief of police and executive leadership, as well This resource aims to support as decision-makers in senior law enforcement agencies to Organizational management positions determine how well equipped Readiness outside the executive they are to adopt responsible Assessment leadership, particularly those AI innovation, reflecting upon Questionnaire in technology and innovation the guidance provided in the units that are responsible Organizational Roadmap. for the deployment of AI systems. This resource aims to help law enforcement agencies to identify and evaluate The teams or staff members Risk the risks that an AI system within an agency that are Assessment may pose to individuals and responsible for an AI system Questionnaire communities if the Principles at each stage of the life cycle. for Responsible AI Innovation are not sufficiently fulfilled. This resource serves as a basis to support law enforcement agencies in implementing and The teams or staff members Responsible AI operationalizing responsible within an agency that are Innovation in AI innovation and responsible for an AI system Action Workbook documenting the decisions at each stage of the life cycle. taken throughout the life cycle of an AI system. 12

### ## Page 14
README File The resource is intended to be used in conjunction with the other AI Toolkit resources. Technical It provides explanations of Anyone using the AI Toolkit. Reference Book key concepts and terms, as well as associated fields, and examples which are relevant to law enforcement. WHEN IS THE AI TOOLKIT APPLICABLE? There are many different ways in which AI systems can be used in law enforcement, and some are more likely to raise issues than others. In fact, with the growing prevalence of AI, it is highly likely that many law enforcement agencies will already be making extensive use of AI systems or systems that include some AI components. However, such systems will generally not have been specially produced for or exclusively used in a law enforcement context. Some examples are the use of email spam filters, navigation apps or even face ID to unlock service-issue smart phones. The question that arises is therefore whether the guidance, recommendations and considerations in the AI Toolkit apply to all law enforcement interactions with AI or only for specific systems, tools and technologies that are above a particular ‘threshold’. Given the rapid advancements in this field, the specific impact and risk of any single AI system cannot be determined solely by looking at the nature of the use case itself or whether it was especially developed for the law enforcement context. On the contrary, understanding and managing the risks that may derive from implementing AI systems in law enforcement involves a consideration of a diverse range of circumstances. In practical terms, this means that there can be no definitive ‘threshold’ to establish when the AI Toolkit should be consulted or when its guidance, recommendations and considerations should be acted upon. Despite this, given their nature, the core principles for responsible AI innovation can be considered applicable to all uses of AI systems and at all stages of the life cycle. They are general principles designed to be adaptable to different contexts, and respecting them will contribute to promoting good practices as agencies leverage the positive potential of using AI systems. With regard to the 13

### ## Page 15
README File applicability of the guidance, recommendations and considerations in the rest of the AI Toolkit, agencies should consider the following three questions: 1. Does the use of the AI system pertain to the execution of the core functions of the law enforcement agency, namely, to protect the community, prevent and investigate crime, and ensure justice? 2. Having completed the Risk Assessment Questionnaire, have medium, high, or extremely high risks pertaining to the AI system been identified? 3. In the event that the AI system has been identified as presenting a low risk, are there any other potential effects on human rights that would necessitate considering the full application of the AI Toolkit? If the answer to any of these three questions is yes, then the recommendation is to take into account the guidance, recommendations and considerations contained within the AI Toolkit to the fullest extent possible. How did the AI Toolkit come about? The AI Toolkit was developed by INTERPOL and UNICRI in response to calls for support from the global law enforcement community. The idea for the AI Toolkit initially emerged from the first INTERPOL-UNICRI Global Meeting on AI for Law Enforcement in July 2018, during which participating representatives from the law enforcement community flagged their concerns regarding the challenges they faced in ensuring the responsible use of AI. Recognizing this need, INTERPOL and UNICRI undertook the task of bridging the gap in the guidance for law enforcement agencies on using AI responsibly and in a way which aligns with human rights and ethical principles. The AI Toolkit has been developed through a highly inclusive, consultative, and iterative process. This process has been specifically designed with a view to ensuring that the AI Toolkit is technically and operationally sound, promoting close interdisciplinary coordination with industry, academia, criminal justice practitioners, civil society organizations and the general public, and fostering a sense of transparency and a broader acceptance of the use of AI in law enforcement The development process has included several notable components: 14

### ## Page 16
README File The Core Group of Experts: INTERPOL and UNICRI established this group as an informal external review body to support and guide the development of the AI Toolkit from a substantive perspective. It was comprised of 56 experts from law enforcement, academia, the private sector, and civil society from over 30 different countries. The Core Group of Experts was convened in a virtual format on six occasions during the development process. Stakeholder Consultation & Engagement: INTERPOL and UNICRI carried out regular consultations with representatives of the law enforcement community throughout the development of the AI Toolkit. In addition, specific group consultation sessions were organized with criminal justice practitioners, representatives from the human rights community, and technology providers. When necessary, individual subject matter experts/boards/organizations were also contacted on an ad-hoc basis for additional consultation on specific topics. Finally, as public engagement, trust, and law enforcement transparency play a vital role in the concept of responsible AI innovation, a global public opinion survey was conducted to map public perceptions of the use of AI systems by law enforcement agencies, and consultations were organized on specific public concerns around groups in vulnerable circumstances. Feedback received during this process informed the drafting of the sections of the AI Toolkit which address the importance of public engagement. Peer Review: Ahead of the AI Toolkit’s public release (V1.), INTERPOL and UNICRI facilitated a technical review of the AI Toolkit involving more than 30 experts with backgrounds in law enforcement, academia, human rights, industry, criminal justice, the public sector, and international organizations from across the globe. During this process, detailed feedback on each of the resources was received and integrated into the AI Toolkit. Testing the AI Toolkit in a Practical Setting: To complement the technical peer review, the AI Toolkit has undergone testing by national and local law enforcement agencies from 15 different countries, identified in response to a call for volunteers issued by INTERPOL to all its member countries. Feedback received from testing countries has been compiled and used to improve the AI Toolkit, resulting in the current revised version. 15

### ## Page 17
README File ACKNOWLEDGMENTS INTERPOL and UNICRI would like to express their deep appreciation to the many experts from within the law enforcement community and other national authorities, as well as industry, academia, civil society, and international and regional organizations, that have devoted their time, insights and perspectives to the process of developing the AI Toolkit. Their contribution is invaluable and has been pivotal in shaping the AI Toolkit and ensuring its content is technically accurate, comprehensive from all perspectives, understandable, and implementable by law enforcement agencies. INTERPOL and UNICRI would also like to specifically thank the law enforcement agencies who participated in testing the AI Toolkit, helping to ensure that it is a practical and useful set of resources that will benefit the law enforcement community. Without the collective contributions and collaboration of all those involved, the AI Toolkit would not have been possible. This collaborative effort is a testament to the strength of international cooperation, and it demonstrates the shared commitment of all involved to ensuring that responsible AI innovation is the future of policing.

### Images on this page:
\[image\]: media\Read_ME_File_Feb24\page-17-img-1.png

### ## Page 18
How to cite this publication: UNICRI and INTERPOL. (Revised February 2024). Toolkit for Responsible AI Innovation in Law Enforcement: README file. © United Nations Interregional Crime and Justice Research Institute (UNICRI), 2024 © International Criminal Police Organization (INTERPOL), 2024

### ## Page 19
### README File www.ai-lawenforcement.org XVIII
### Images on this page:
\[image\]: media\Read_ME_File_Feb24\page-19-img-1.png

\[image\]: media\Read_ME_File_Feb24\page-19-img-2.png

\[image\]: media\Read_ME_File_Feb24\page-19-img-3.png

\[image\]: media\Read_ME_File_Feb24\page-19-img-4.png

\[image\]: media\Read_ME_File_Feb24\page-19-img-5.png
